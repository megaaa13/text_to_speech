{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow WaveGlow inference\n",
    "\n",
    "The training procedure of WaveGlow is **not** implemented yet. This notebook will show how to create the `pretrained WaveGlow` in `tensorflow` and use it as `vocoder` in the `tts` API. \\*\n",
    "\n",
    "Currently it seems that the `tensorflow` version is slower than the `pytorch` one even in graph mode so I suggest you to not use it now if you do not need it.\n",
    "\n",
    "The advantage is that both synthesizer and vocoder are in tensorflow so you do not need to limit tensorflow GPU memory (see `text_to_speech` for more information). Another advantage is that you do not need a working installation of `pytorch` on GPU (which can be a gread advantage due to differences between `tensorflow` and `pytorch` for `CUDA / CuDNN` versions). \n",
    "\n",
    "\\* You can also simply download the model (link in the `README`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing submodel : vocoder !\n",
      "Submodel vocoder saved in pretrained_models\\WaveGlow\\saving\\vocoder.json !\n",
      "Model WaveGlow initialized successfully !\n",
      "Weights transfered successfully !\n",
      "Weights converted successfully !\n",
      "Submodel vocoder saved in pretrained_models\\WaveGlow\\saving\\vocoder.json !\n",
      "\n",
      "========== WaveGlow ==========\n",
      "Sub model vocoder\n",
      "- Inputs \t: unknown\n",
      "- Outputs \t: unknown\n",
      "- Number of layers \t: 25\n",
      "- Number of parameters \t: 268.000 Millions\n",
      "- Model not compiled\n",
      "\n",
      "Transfer-learning from : pytorch_nvidia_waveglow\n",
      "Already trained on 0 epochs (0 steps)\n",
      "\n",
      "Audio rate : 22050\n",
      "Mel channels : 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.tts import WaveGlow\n",
    "\n",
    "waveglow = WaveGlow.build_from_nvidia_pretrained()\n",
    "print(waveglow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it as vocoder\n",
    "\n",
    "You can use the exact same method but you must specify `vocoder` and `vocoder_class` arguments. \n",
    "\n",
    "- `vocoder` is the name of your vocoder model\n",
    "- `vocoder_class` is the class of the vocoder model (by default it is `PtWaveGlow` which is an utilityclass for the pytorch pretrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts, WaveGlow\n",
    "\n",
    "text = [\n",
    "    \"Hello world ! Hope you will enjoy this funny API for Text-To-Speech !\",\n",
    "    \"If you train new models, do not hesitate to contact me or add it in the available models !\"\n",
    "]\n",
    "\n",
    "tts(\n",
    "    text, lang = 'en', vocoder_class = WaveGlow,\n",
    "    vocoder_batch_size = 2, # note that this keyword is also supported by the pytorch model\n",
    "    directory = None, display = True, debug = True, tqdm = lambda x: x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
