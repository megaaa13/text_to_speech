{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Speech inference with my funny API\n",
    "\n",
    "This notebook shows how to use the `tts` module as API to make complete inference with your pretrained `Tacotron-2` model as `synthesizer` and pretrained `NVIDIA's Waveglow` as `vocoder`\n",
    "\n",
    "The API is really easy to use ! Just call the function with your sentence(s) and the model you want to use and that's it ! The code will automatically load the right model and make the whole inference !\n",
    "\n",
    "You can also associate models to language in the `models/tts/__init__.py` file in order to enable language-based loading (instead of model-based loading) (see 2nd cell for example)\n",
    "\n",
    "Note that `Vocoder` is loaded as global variable and all `BaseModel` are `singleton` so you can call the function as mny times as you want without reloading models every time !\n",
    "\n",
    "I left the results in the `example_outputs/` directory so that you can listen to them without re-executing the code ;)\n",
    "\n",
    "PS : I will (*theorically*) **never** share weights for the last french demonstration in this notebook (which is a `fine-tuned SV2TTS`) but will share other french voices trained on `SIWIS` (single-speaker) and `SIWIS + CommonVoice + VoxForge` (multi-speaker) [1]\n",
    "\n",
    "Note : it is normal that the 1st generation is relatively slow but the next ones will be faster than real time !\n",
    "\n",
    "## Steps to reproduce\n",
    "\n",
    "1. Download model weights (see README.md for links)\n",
    "2. Unzip weights in `pretrained_models/` directory\n",
    "3. Execute cells !\n",
    "\n",
    "Note : to associate a model to a language, go to `models/tts/__init__.py` and modify the `_pretrained` global variable (at the end of the file). The `key` is the language and the `value` is de model's name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "This functionality allows you to enter text and get the output directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts_stream\n",
    "\n",
    "# I suggest you to not save audios when streaming because it is slower ;)\n",
    "# I did it so that you can listen to the result\n",
    "\n",
    "# PS : the 'goodbye, see you soon !' message at the end is a funny sentence I added\n",
    "# when you stop the streaming :D\n",
    "tts_stream(model = 'pretrained_tacotron2', directory = 'example_outputs', overwrite = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTS on text\n",
    "\n",
    "This function generates audios based on the provided text / list of text. \n",
    "\n",
    "By default the model will not regenerate sentences if they were already generated but you can change this behavior with the `overwrite` argument to force regeneration. \n",
    "\n",
    "In this example you can see model loading with `lang = 'en'` which will load the `nvidia_pretrained` model. In the `models/tts/__init__.py` file I associated by default the `en` language with this model. \n",
    "\n",
    "Note on performances : in the `example_waveglow` notebook you can see `1.4 sec generated / sec` with the `tensorflow` implementation of `WaveGlow`. The `pytorch` version achieves `1.7s generated / sec`. Here it achieves `1.4s generated / sec` because I save results (which takes some time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = [\n",
    "    \"Hello world ! Hope you will enjoy this funny API for Text-To-Speech !\",\n",
    "    \"If you train new models, do not hesitate to contact me or add it in the available models !\"\n",
    "]\n",
    "\n",
    "tts(\n",
    "    text, lang = 'en', directory = 'example_outputs', display = True, \n",
    "    overwrite = True, debug = True, tqdm = lambda x: x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = [\n",
    "    \"Bonjour à tous ! J'espère que vous allez aimer cette démonstration de voix en français !\"\n",
    "]\n",
    "\n",
    "tts(\n",
    "    text, lang = 'fr', directory = 'example_outputs', display = True, \n",
    "    overwrite = True, debug = True, tqdm = lambda x: x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = \"Bonjour à tous ! J'espère que vous allez aimer cette démonstration de mon super modèle entrainé avec seulement 20 minutes d'audios !\\\n",
    "Je ne partagerai pas cemodèle mais je trouvais ça intéressant de montrer ce qu'il était possible de faire !\"\n",
    "\n",
    "tts(\n",
    "    text, model = 'sv2tts_fine_tuned', directory = 'example_outputs', display = True, \n",
    "    overwrite = True, debug = True, tqdm = lambda x: x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
