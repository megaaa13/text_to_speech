{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Speech inference with my funny API\n",
    "\n",
    "This notebook shows how to use the `tts` module as API to make complete inference with your pretrained `Tacotron-2` model as `synthesizer` and pretrained `NVIDIA's Waveglow` as `vocoder`\n",
    "\n",
    "The API is really easy to use ! Simply call the function with your sentence(s) and the model you want to use, and that's it ! The code automatically loads the right model and makes the whole inference !\n",
    "\n",
    "You can also associate models to language in the `models/tts/__init__.py` file, in order to enable *language-based* loading (instead of *model-based* loading) (see the 2nd cell for example)\n",
    "\n",
    "Note that `Vocoder` is loaded as global variable, and all `BaseModel` are `singleton`, so you can call the function as mny times as you want without reloading models every time !\n",
    "\n",
    "I left the results in the `example_outputs/` directory such that you can listen to them without re-executing the code ;)\n",
    "\n",
    "Note : it is normal that the 1st generation is relatively slow (because of models' loading and `tensorflow graph` compilation) but the next ones will be faster than real time !\n",
    "\n",
    "PS : I will (*theorically*) **never** share weights for the 2 last french demonstrations in this notebook (which is a `fine-tuned SV2TTS`) but will share other french voices trained on `SIWIS` (single-speaker) and `SIWIS + CommonVoice + VoxForge` (multi-speaker)\n",
    "\n",
    "## Steps to reproduce\n",
    "\n",
    "1. Download model weights (see `README.md` for links)\n",
    "2. Unzip weights in `pretrained_models/` directory\n",
    "3. Execute cells !\n",
    "\n",
    "Note : to associate a model to a language, go to `models/tts/__init__.py` and modify the `_pretrained` global variable (at the end of the file). The `key` is the language and the `value` is de model's name.\n",
    "\n",
    "**Important note** : it is not required to download the `WaveGlow` vocoder model. It is also possible to use the `torch hub` model but it requires a working **GPU-enabled** pytorch installation. If you do not want to have both tensorflow and pytorch working together, you can download the `WaveGlow` tensorflow implementation I made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "This functionality allows you to enter text and get the output directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts_stream\n",
    "\n",
    "# I suggest you to not save audios when streaming because it is slower ;)\n",
    "# I did it so that you can listen to the result\n",
    "\n",
    "# PS : the 'goodbye, see you soon !' message at the end is a funny sentence I added\n",
    "# when you stop the streaming :D\n",
    "tts_stream(model = 'pretrained_tacotron2', directory = 'example_outputs/streaming', overwrite = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text_en = \"I wish you a merry christmas, and all the best for the new year 2023 !\"\n",
    "text_fr = \"Je vous souhaite un joyeux Noël, et tout le meilleur pour cette nouvelle année 2023 !\"\n",
    "\n",
    "_ = tts(\n",
    "    text_en, lang = 'en', directory = 'example_outputs/christmas', display = True, \n",
    "    overwrite = True, debug = True, tqdm = None\n",
    ")\n",
    "_ = tts(\n",
    "    text_fr, model = 'sv2tts_fine_tuned', directory = 'example_outputs/christmas', display = True, \n",
    "    overwrite = True, debug = True, tqdm = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.audio import display_audio\n",
    "\n",
    "_ = display_audio('example_outputs/christmas/sentence_audios/audio_0.mp3')\n",
    "_ = display_audio('example_outputs/christmas/sentence_audios/audio_1.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTS on text\n",
    "\n",
    "This function generates audios based on the provided text / list of text. \n",
    "\n",
    "By default, the model does not regenerate sentences if they have already been generated, but you can change this behavior with the `overwrite` argument to force regeneration. Note that for `SV2TTS`-based models, `overwrite = True` by default as those models are designed to have multiple intonations as they are *multi-speakers* models. \n",
    "\n",
    "In this example, you can see model loading with `lang = 'en'` which will load the `pretrained_tacotron2` model. In the `models/tts/__init__.py` file, I have associated by default the `en` language with this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "from loggers import set_level\n",
    "\n",
    "text = [\n",
    "    \"Hello world ! Hope you will enjoy this funny API for Text-To-Speech !\",\n",
    "    \"If you train new models, do not hesitate to contact me or add it in the available models !\"\n",
    "]\n",
    "\n",
    "set_level('info')\n",
    "\n",
    "_ = tts(\n",
    "    text, lang = 'en', directory = 'example_outputs/en', display = True, \n",
    "    overwrite = True, debug = True, tqdm = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = [\n",
    "    \"Bonjour tout le monde ! J'espère que vous allez aimer cette démonstration de voix en français !\"\n",
    "]\n",
    "\n",
    "_ = tts(\n",
    "    text, lang = 'fr', directory = 'example_outputs/fr', display = True, \n",
    "    overwrite = True, debug = True, tqdm = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import tts\n",
    "\n",
    "text = \"Bonjour tout le monde ! J'espère que vous allez aimer cette démonstration de mon super modèle entrainé avec seulement 20 minutes d'audios ! \\\n",
    "Je ne partagerai pas ce modèle, mais je trouvais ça intéressant de montrer ce qu'il était possible de faire !\"\n",
    "\n",
    "_ = tts(\n",
    "    text, model = 'sv2tts_fine_tuned', directory = 'example_outputs/fr', display = True, \n",
    "    overwrite = False, debug = True, tqdm = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell allows to display an audio based on its saving directory and the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts import get_audio_file\n",
    "from utils.audio import display_audio\n",
    "\n",
    "text1 = \"Bonjour tout le monde ! J'espère que vous allez aimer cette démonstration de mon super modèle entrainé avec seulement 20 minutes d'audios ! \\\n",
    "Je ne partagerai pas ce modèle, mais je trouvais ça intéressant de montrer ce qu'il était possible de faire !\"\n",
    "\n",
    "text2 = \"Bonjour tout le monde ! J'espère que vous allez aimer cette démonstration de mon super modèle entrainé avec seulement 5 minutes d'audios !\\\n",
    "Je ne partagerai pas cemodèle, mais je trouvais ça intéressant de montrer ce qu'il était possible de faire !\"\n",
    "\n",
    "_ = display_audio(get_audio_file(text1, directory = 'example_outputs/fr'))\n",
    "\n",
    "_ = display_audio(get_audio_file(text2, directory = 'example_outputs/fr'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
